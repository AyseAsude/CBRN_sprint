model:
  name: "meta-llama/Llama-3.1-8B-Instruct"
  max_length: 2048
  device: "auto"

classifier:
  hidden_sizes: [256, 128, 64]
  dropout_prob: 0.1

training:
  batch_size: 4
  learning_rate: 0.001
  num_epochs: 15
  warmup_ratio: 0.1
  weight_decay: 0.01
  patience: 5

data:
  benign_path: ["datasets/cbrn_train.json"]
  harmful_path: ["datasets/harmful_train.json"]
  val_split: 0.1
  use_output: false

seed: 42
output_path: "llama_output_instruction_only/"
